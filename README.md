# AI Tool Calling Application
## Ollama + Qwen3 + MCP Architecture

A pure Python AI application that uses Ollama with Qwen3 model and Model Context Protocol (MCP) for tool calling.

## Features
- ğŸ¤– **Ollama + Qwen3**: Local AI model (no OpenAI needed)
- ğŸ”§ **MCP Tools**: Calculator and Weather tools
- ğŸ  **100% Local**: No external API dependencies
- ğŸš€ **Fast Setup**: Automated installation script

## Quick Start

### 1. Setup (Run Once)
\`\`\`bash
python setup.py
\`\`\`

### 2. Run Application (3 Terminals)

**Terminal 1 - Ollama:**
\`\`\`bash
ollama serve
\`\`\`

**Terminal 2 - MCP Server:**
\`\`\`bash
python mcp_server/server.py
\`\`\`

**Terminal 3 - Main App:**
\`\`\`bash
python app.py
\`\`\`

## Test Queries
- `What is 25 + 17?` (Calculator tool)
- `Tell me the temperature in Pune` (Weather tool)
- `Hello!` (Direct response, no tool)

## Project Structure
\`\`\`
â”œâ”€â”€ app.py                 # Main application
â”œâ”€â”€ mcp_client/           # MCP client package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ client.py
â”œâ”€â”€ mcp_server/           # MCP server package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py         # FastAPI server
â”‚   â””â”€â”€ tools.py          # Tool implementations
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.json       # Configuration
â”‚   â””â”€â”€ modelfile         # Ollama model config
â”œâ”€â”€ setup.py              # Setup script
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md
\`\`\`

## How It Works
1. **User Query** â†’ Main app (`app.py`)
2. **Tool Decision** â†’ Ollama + Qwen3 decides if tool needed
3. **Tool Execution** â†’ MCP Client â†’ MCP Server â†’ Tool
4. **Final Answer** â†’ Qwen3 generates response using tool result

## Requirements
- Python 3.8+
- Ollama installed and running
- Internet connection (for initial model download)

## Troubleshooting
- **Ollama not found**: Install from https://ollama.ai
- **Model not found**: Run `python setup.py` again
- **Connection refused**: Make sure all 3 terminals are running
